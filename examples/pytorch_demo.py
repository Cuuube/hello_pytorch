#!/usr/bin/env python
# -*- coding: utf-8 -*-
# @Author  : zxod
# @Time    : 2022/07/17 10:50
# æœ¬æ¨¡å—æ˜¯å¯¹å®˜ç½‘demoçš„å®è·µï¼šhttps://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html

import os
from pickletools import optimize
from turtle import pd

import matplotlib.pyplot as plt
import torch
from torch import nn
from torch.utils.data import DataLoader, Dataset
from torchvision import datasets
from torchvision.io import read_image
from torchvision.transforms import ToTensor

DATALOADER_BATCH_SIZE = 64
CLASSES = [
    "Tæ¤è¡«",
    "è£¤å­",
    "å¥—è¡«",
    "è£™å­",
    "å¤–å¥—",
    "å‡‰é‹",
    "è¡¬è¡«",
    "å¸†å¸ƒé‹",
    "åŒ…",
    "çŸ­é´",
]
CLASSES_EN = [
    "T-shirt/top",
    "Trouser",
    "Pullover",
    "Dress",
    "Coat",
    "Sandal",
    "Shirt",
    "Sneaker",
    "Bag",
    "Ankle boot",
]


def get_training_data():
    '''
        ä»å®˜ç½‘ä¸‹è½½è®­ç»ƒæ•°æ®ï¼Œéœ€è¦ğŸªœã€‚
        è¿™ä¸ªæ•°æ®é›†æ˜¯28*28åƒç´ çš„é»‘ç™½å›¾ç‰‡ã€‚
        https://pytorch.org/tutorials/beginner/basics/data_tutorial.html
    '''
    training_data = datasets.FashionMNIST(
        root="data",
        train=True,
        download=True,
        transform=ToTensor(),
    )
    return training_data

def get_test_data():
    '''ä»å®˜ç½‘ä¸‹è½½æµ‹è¯•æ•°æ®ï¼Œéœ€è¦ğŸªœ'''
    test_data = datasets.FashionMNIST(
        root="data",
        train=False,
        download=True,
        transform=ToTensor(),
    )
    return test_data

def gen_dataloader(dataset):
    '''ç”Ÿæˆdataloader'''
    dataloader = DataLoader(dataset, batch_size=DATALOADER_BATCH_SIZE)
    return dataloader

def print_data(dataloader):
    '''æ‰“å°ä¸‹è½½ä¸‹æ¥çš„æ•°æ®é›†çš„Xå’Œyæ•°æ®åŠç±»å‹'''
    print(f"========æ‰§è¡Œæ‰“å°å®˜æ–¹æ•°æ®é›†========")
    for X, y in dataloader:
        print(f"Shape of X [N, C, H, W]: {X.shape}")
        print(f"Shape of y: {y.shape} {y.dtype}")
    print(f"========æ‰§è¡Œæ‰“å°å®Œæ¯•========")


def load_all_data():
    '''æ‹‰è®­ç»ƒæ¨¡å‹å…¨éƒ¨æ•°æ®'''
    get_training_data()
    get_test_data()


def view_training_data_figure(training_data):
    '''æŸ¥çœ‹è®­ç»ƒæ•°æ®çš„å›¾åƒ'''
    figure = plt.figure(figsize=(8,8))
    cols, rows = 3,3
    # è®­ç»ƒæ•°æ®ä¸­éšæœºæŠ½å–9ä¸ªå›¾ï¼Œç»„æˆ3*3
    for i in range(1, cols*rows+1):
        sample_idx = torch.randint(len(training_data), size=(1,)).item()
        img, label = training_data[sample_idx]
        figure.add_subplot(rows, cols, i)
        plt.title(CLASSES_EN[label])
        plt.axis("off")
        plt.imshow(img.squeeze(), cmap="gray")
    plt.show()


# -------------------------------------------------------------
# https://pytorch.org/tutorials/beginner/basics/data_tutorial.html

class CustomImageDataset(Dataset):
    '''è‡ªå®šä¹‰æ•°æ®é›†
    '''
    def __init__(self, annotations_file, img_dir, transform=None, label_transform=None) -> None:
        self.img_labels = pd.read_csv()
        self.img_dir = img_dir
        self.transform = transform
        self.label_transform = label_transform

    def __len__(self):
        return len(self.img_labels)

    def __getitem__(self, idx):
        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])
        image = read_image(img_path)
        label = self.img_labels.iloc[idx, 1]
        if self.transform:
            image = self.transform(image)
        if self.label_transform:
            label = self.label_transform(label)
        return image, label



# -------------------------------------------------------------


def get_device() -> str:
    '''æ£€æŸ¥è®¾å¤‡æ˜¯å¦æ”¯æŒnvidia cuda'''
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"Device: {device} ")
    return device


class NeuralNetwork(nn.Module):
    '''ä¸‰å±‚ç¥ç»ç½‘ç»œæ¶æ„'''

    def __init__(self) -> None:
        super(NeuralNetwork, self).__init__()

        HEIGHT = 28
        WIDTH = 28
        first_in_features = HEIGHT * WIDTH
        first_out_features = 512
        second_in_features = first_out_features
        second_out_features = 512
        third_in_features = second_out_features
        third_out_features = len(CLASSES) # æœ€ç»ˆè¾“å‡ºå’Œåˆ†ç±»æ•°é‡ä¿æŒä¸€è‡´

        # æ•´æµå‡½æ•°ä½¿ç”¨ReLUã€‚https://baike.baidu.com/item/ReLU%20%E5%87%BD%E6%95%B0/22689567
        self.flatten = nn.Flatten()
        self.linear_relu_stack = nn.Sequential(
            nn.Linear(first_in_features, first_out_features),
            nn.ReLU(), # ReLUï¼ˆLinear rectification functionï¼‰çº¿æ€§æ•´æµå‡½æ•°ï¼šçº¿æ€§çš„æ¿€æ´»å‡½æ•°
            nn.Linear(second_in_features, second_out_features),
            nn.ReLU(),
            nn.Linear(third_in_features, third_out_features)
        )

    def forward(self, x):
        x = self.flatten(x)
        logits = self.linear_relu_stack(x)
        return logits

    def save(self, filename):
        model_root_path = "models/"
        path = model_root_path+filename
        torch.save(self.state_dict(), path)
        print(f"Model saved at {path}")

    def load(self, filename):
        model_root_path = "models/"
        path = model_root_path+filename
        self.load_state_dict(torch.load(path))
        print(f"Model loaded from {path}")

    @staticmethod
    def new():
        device = get_device()
        model = NeuralNetwork().to(device)
        return model


# -------------------------------------------------------------

def train_model(dataloader, model, loss_fn, optimizer):
    '''ç”¨è®­ç»ƒé›†è®­ç»ƒæ¨¡å‹'''
    device = get_device()
    size = len(dataloader.dataset)
    model.train()
    for batch, (X, y) in enumerate(dataloader):
        # ???
        X = X.to(device)
        y = y.to(device)

        # è®¡ç®—é¢„æµ‹è¯¯å·®
        pred = model(X)
        loss = loss_fn(pred, y)

        # åå‘ä¼ æ’­
        optimizer.zero_grad() # ???
        loss.backward()
        optimizer.step()

        # è®­ç»ƒ100æ¬¡æ‰“å°ä¸€ä¸‹æ—¥å¿—
        if batch % 100 == 0:
            loss = loss.item()
            current = batch * len(X)
            print(f"loss: {loss:>7f} [{current:>5d}/{size:>5d}]")

def test_model(dataloader, model, loss_fn):
    '''ç”¨æµ‹è¯•é›†æµ‹è¯•æ¨¡å‹æ•ˆæœ'''
    device = get_device()
    size = len(dataloader.dataset)
    num_batches = len(dataloader)
    model.eval() # ???

    test_loss, correct = 0, 0
    with torch.no_grad():
        for X, y in dataloader:
            X = X.to(device) # æŠŠå¼ é‡æ”¾åˆ°gpuæˆ–cpuä¸Š
            y = y.to(device)
            pred = model(X) # æ¨¡å‹é¢„æµ‹
            test_loss += loss_fn(pred, y).item() # è®¡ç®—é¢„æµ‹æŸå¤±
            correct += (pred.argmax(1) == y).type(torch.float).sum().item()

    test_loss /= num_batches
    correct /= size
    print(f"Test Error:\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f}\n")


def do_train_model(model_name):
    '''æ‰§è¡Œè®­ç»ƒæˆ‘ä»¬çš„æ¨¡å‹'''
    # åŠ è½½æ•°æ®é›†
    training_dataloader = gen_dataloader(get_training_data())
    test_dataloader = gen_dataloader(get_test_data())
    print_data(test_dataloader)

    # æ–°å»ºæ¨¡å‹
    model = NeuralNetwork.new()
    # print(model)

    # å®šä¹‰æŸå¤±å‡½æ•°ã€‚æŸå¤±å‡½æ•°ï¼šè¡¡é‡è¾“å‡ºå’Œé¢„æœŸå€¼ä¹‹é—´çš„è·ç¦»ã€‚
    loss_fn = nn.CrossEntropyLoss()
    # å®šä¹‰ä¼˜åŒ–å™¨ã€‚ä¼˜åŒ–å™¨ï¼šæ ¹æ®æŸå¤±å‡½æ•°è®¡ç®—çš„é¢„æœŸè·ç¦»å€¼ï¼Œä½œä¸ºåé¦ˆä¿¡å·å¯¹æƒé‡è¿›è¡Œå¾®è°ƒã€‚ä»¥é™ä½æŸå¤±å€¼ã€‚
    lr = 1e-3
    optimizer = torch.optim.SGD(model.parameters(), lr=lr)

    # æ‰§è¡Œ5è½®è®­ç»ƒ
    epochs = 5
    for t in range(epochs):
        print(f"Epoch {t+1}\n-----------------------")
        train_model(training_dataloader,model,loss_fn,optimizer)
        test_model(test_dataloader, model, loss_fn)
    print("Training Done!")

    # å†™å‡ºæ¨¡å‹
    model.save(model_name)


def do_predict(model_name):
    device = get_device()
    # åˆå§‹åŒ–æ¨¡å‹
    model = NeuralNetwork.new()
    # åŠ è½½æ¨¡å‹
    model.load(model_name)
    model.eval()

    test_data = get_test_data()

    # åˆå§‹åŒ–ç”»å¸ƒï¼Œç”¨ä½œè¾“å‡ºé¢„æµ‹æ•ˆæœ
    figure = plt.figure(figsize=(8,8))
    cols, rows = 3,3

    # è®­ç»ƒæ•°æ®ä¸­éšæœºæŠ½å–9ä¸ªå›¾ï¼Œç»„æˆ3*3
    for i in range(1, cols*rows+1):
        # æµ‹è¯•é›†ä¸­å–éšæœºæ•°
        sample_idx = torch.randint(len(test_data), size=(1,)).item()
        img, label_idx = test_data[sample_idx] # å–å‡ºå›¾ç‰‡tensorå’Œç»“æœ
        label = CLASSES_EN[label_idx]

        # æ‰§è¡Œé¢„æµ‹
        with torch.no_grad():
            pred = model(img.to(device))
            predicted_label = CLASSES_EN[pred[0].argmax(0)]
            print(f'Predicted: "{predicted_label}", Actual: "{label}"')

            # å†™å‡ºå›¾ç‰‡
            figure.add_subplot(rows, cols, i)
            plt.title(f'p:{predicted_label};r:{label}')
            plt.axis("off")
            plt.imshow(img.squeeze(), cmap="gray")

    # å±•ç¤ºå›¾ç‰‡
    plt.show()

    # # æ‹¿ä¸€ä¸ªå¾…é¢„æµ‹æ•°æ®ã€‚ä»ç°æœ‰çš„test_dataä¸­é€‰ä¸€ä¸ª
    # x, y = test_data[0][0], test_data[0][1]
    # with torch.no_grad():
    #     # æ‰§è¡Œé¢„æµ‹
    #     pred = model(x)
    #     # æ‰“å°é¢„æµ‹ç»“æœå’Œå®é™…ç»“æœ
    #     predicted, actual = CLASSES[pred[0].argmax(0)], CLASSES[y]
    #     print(f'Predicted: "{predicted}", Actual: "{actual}"')


 
# -------------------------------------------------------------


def run():
    # åŠ è½½å®˜æ–¹è®­ç»ƒé›†å’Œæµ‹è¯•é›†ï¼Œå¹¶æ‰“å°
    # load_all_data()
    # print_data()
    # view_training_data_figure(get_training_data())

    # æ–°å»ºæœªè®­ç»ƒæ¨¡å‹
    # model = NeuralNetwork.new()
    # print(model)

    # è®­ç»ƒæ¨¡å‹å¹¶å†™å…¥æ–‡ä»¶
    model_name = "pytorch_demo_model.pth"
    do_train_model(model_name)
    # åšé¢„æµ‹
    do_predict(model_name)

